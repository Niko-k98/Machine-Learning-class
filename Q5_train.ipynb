{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Q5_train",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Niko-k98/Machine-Learning-class/blob/main/Q5_train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oQvY2I6dDUt6"
      },
      "source": [
        "import re\n",
        "import numpy as np\n",
        "from pickle import dump\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.layers import LSTM\n",
        "import pandas\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yEGW-YXxDV-X"
      },
      "source": [
        "# Load and clean a text file\n",
        "def fClean_Load(filename):\n",
        "    file = open(filename, encoding=\"utf8\", errors='ignore') \n",
        "    #file = open(filename, 'rb')\n",
        "    text = file.read()\n",
        "    file.close()\n",
        "    # Clean text\n",
        "    words = re.findall(r'[a-z\\.]+', text.lower())\n",
        "    return ' '.join(words)\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wWucJCEdDZVT"
      },
      "source": [
        "# load text / Complete novel \"A Tale of Two Cities\"\n",
        "raw_text = fClean_Load('AToTC.txt')"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "osJWNvdNDbmP",
        "outputId": "c6206322-9ac1-40fb-fe32-63423cef9032",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# organize into sequences of characters\n",
        "\n",
        "length = 100\n",
        "lines = list()\n",
        "for i in range(length, len(raw_text)):\n",
        "    seq = raw_text[i-length:i+1]\n",
        "    lines.append(seq)\n",
        "print('Total lines: %d' % len(lines))\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total lines: 729489\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cp7eSMm-EnYN"
      },
      "source": [
        "chars = sorted(list(set(''.join(lines))))\n",
        "mapping = dict((c, i) for i, c in enumerate(chars))\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_VOSdLhEpud"
      },
      "source": [
        "sequences = list()\n",
        "for line in lines:\n",
        "\tencoded_seq = [mapping[char] for char in line]\n",
        "\tsequences.append(encoded_seq)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_lBQKVxJErnR",
        "outputId": "93b47567-5090-43a9-b552-0c9788317611",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# vocabulary size\n",
        "vocab_size = len(mapping)\n",
        "print('Vocabulary Size: %d' % vocab_size)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocabulary Size: 28\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g53a6fK_Et7c"
      },
      "source": [
        "sequences = np.array(sequences)\n",
        "X, y = sequences[:,:-1], sequences[:,-1]"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SnzIKVHxEwbw"
      },
      "source": [
        "#X = X / float(vocab_size)\n",
        "#X = np.reshape(X, (X.shape[0], length, 1))\n",
        "#y = to_categorical(y, num_classes=vocab_size)\n",
        "sequences = np.array(sequences)\n",
        "X1, y = sequences[:,:-1], sequences[:,-1]\n",
        "temp = [to_categorical(x, num_classes=vocab_size) for x in X1]\n",
        "X = np.array(temp)\n",
        "y = to_categorical(y, num_classes=vocab_size)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HV3DRkbzEzer",
        "outputId": "a41d633a-f943-4674-8c6f-c34aa6fa0cc7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "##############################################################################\n",
        "####################### Select and fit an appropriate model ##################\n",
        "# 1) LSTM size, 2) Dropout, 3) epochs, and 4) batch_size #####################\n",
        "##############################################################################\n",
        "\n",
        "model = Sequential()\n",
        "model.add(LSTM(1024  ,input_shape=(X.shape[1], X.shape[2])))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(vocab_size, activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "print(model.summary())"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_16 (LSTM)               (None, 1024)              4313088   \n",
            "_________________________________________________________________\n",
            "dropout_9 (Dropout)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 28)                28700     \n",
            "=================================================================\n",
            "Total params: 4,341,788\n",
            "Trainable params: 4,341,788\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B7k01MyhE4O9",
        "outputId": "8c0316ff-faae-479c-fe1a-c01445a25ced",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "history=model.fit(X, y, epochs=50, verbose=1, batch_size=128 )\n"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "5700/5700 [==============================] - 365s 64ms/step - loss: 1.4067 - accuracy: 0.5642\n",
            "Epoch 2/50\n",
            "5700/5700 [==============================] - 364s 64ms/step - loss: 1.2897 - accuracy: 0.5963\n",
            "Epoch 3/50\n",
            "5700/5700 [==============================] - 364s 64ms/step - loss: 1.2251 - accuracy: 0.6145\n",
            "Epoch 4/50\n",
            "5700/5700 [==============================] - 364s 64ms/step - loss: 1.1743 - accuracy: 0.6282\n",
            "Epoch 5/50\n",
            "5700/5700 [==============================] - 363s 64ms/step - loss: 1.1352 - accuracy: 0.6397\n",
            "Epoch 6/50\n",
            "5700/5700 [==============================] - 364s 64ms/step - loss: 1.1000 - accuracy: 0.6494\n",
            "Epoch 7/50\n",
            "5700/5700 [==============================] - 363s 64ms/step - loss: 1.0689 - accuracy: 0.6582\n",
            "Epoch 8/50\n",
            "5700/5700 [==============================] - 363s 64ms/step - loss: 1.0410 - accuracy: 0.6664\n",
            "Epoch 9/50\n",
            "5700/5700 [==============================] - 363s 64ms/step - loss: 1.0161 - accuracy: 0.6740\n",
            "Epoch 10/50\n",
            "5700/5700 [==============================] - 363s 64ms/step - loss: 0.9932 - accuracy: 0.6803\n",
            "Epoch 11/50\n",
            "5700/5700 [==============================] - 363s 64ms/step - loss: 0.9725 - accuracy: 0.6869\n",
            "Epoch 12/50\n",
            "5700/5700 [==============================] - 363s 64ms/step - loss: 0.9525 - accuracy: 0.6925\n",
            "Epoch 13/50\n",
            "5700/5700 [==============================] - 362s 64ms/step - loss: 0.9360 - accuracy: 0.6975\n",
            "Epoch 14/50\n",
            "5700/5700 [==============================] - 363s 64ms/step - loss: 0.9193 - accuracy: 0.7025\n",
            "Epoch 15/50\n",
            "5700/5700 [==============================] - 363s 64ms/step - loss: 0.9044 - accuracy: 0.7073\n",
            "Epoch 16/50\n",
            "5700/5700 [==============================] - 363s 64ms/step - loss: 0.8896 - accuracy: 0.7120\n",
            "Epoch 17/50\n",
            "5700/5700 [==============================] - 362s 64ms/step - loss: 0.8764 - accuracy: 0.7156\n",
            "Epoch 18/50\n",
            "5700/5700 [==============================] - 363s 64ms/step - loss: 0.8640 - accuracy: 0.7200\n",
            "Epoch 19/50\n",
            "5700/5700 [==============================] - 363s 64ms/step - loss: 0.8511 - accuracy: 0.7240\n",
            "Epoch 20/50\n",
            "5700/5700 [==============================] - 363s 64ms/step - loss: 0.8381 - accuracy: 0.7282\n",
            "Epoch 21/50\n",
            "5700/5700 [==============================] - 363s 64ms/step - loss: 0.8261 - accuracy: 0.7312\n",
            "Epoch 22/50\n",
            "5700/5700 [==============================] - 363s 64ms/step - loss: 0.8155 - accuracy: 0.7347\n",
            "Epoch 23/50\n",
            "5700/5700 [==============================] - 363s 64ms/step - loss: 0.8040 - accuracy: 0.7391\n",
            "Epoch 24/50\n",
            "5700/5700 [==============================] - 363s 64ms/step - loss: 0.7924 - accuracy: 0.7426\n",
            "Epoch 25/50\n",
            "5700/5700 [==============================] - 363s 64ms/step - loss: 0.7809 - accuracy: 0.7457\n",
            "Epoch 26/50\n",
            "5700/5700 [==============================] - 363s 64ms/step - loss: 0.7698 - accuracy: 0.7493\n",
            "Epoch 27/50\n",
            "5700/5700 [==============================] - 363s 64ms/step - loss: 0.7588 - accuracy: 0.7531\n",
            "Epoch 28/50\n",
            "5700/5700 [==============================] - 363s 64ms/step - loss: 0.7472 - accuracy: 0.7566\n",
            "Epoch 29/50\n",
            "5700/5700 [==============================] - 362s 64ms/step - loss: 0.7385 - accuracy: 0.7591\n",
            "Epoch 30/50\n",
            "5700/5700 [==============================] - 363s 64ms/step - loss: 0.7286 - accuracy: 0.7624\n",
            "Epoch 31/50\n",
            "5700/5700 [==============================] - 363s 64ms/step - loss: 0.7161 - accuracy: 0.7669\n",
            "Epoch 32/50\n",
            "5700/5700 [==============================] - 363s 64ms/step - loss: 0.7078 - accuracy: 0.7696\n",
            "Epoch 33/50\n",
            "5700/5700 [==============================] - 363s 64ms/step - loss: 0.6976 - accuracy: 0.7727\n",
            "Epoch 34/50\n",
            "5700/5700 [==============================] - 363s 64ms/step - loss: 0.6884 - accuracy: 0.7755\n",
            "Epoch 35/50\n",
            "5700/5700 [==============================] - 363s 64ms/step - loss: 0.6746 - accuracy: 0.7799\n",
            "Epoch 36/50\n",
            "5700/5700 [==============================] - 362s 64ms/step - loss: 0.6678 - accuracy: 0.7820\n",
            "Epoch 37/50\n",
            "5700/5700 [==============================] - 362s 64ms/step - loss: 0.6592 - accuracy: 0.7849\n",
            "Epoch 38/50\n",
            "5700/5700 [==============================] - 363s 64ms/step - loss: 0.6494 - accuracy: 0.7875\n",
            "Epoch 39/50\n",
            "5700/5700 [==============================] - 363s 64ms/step - loss: 0.6395 - accuracy: 0.7911\n",
            "Epoch 40/50\n",
            "5700/5700 [==============================] - 363s 64ms/step - loss: 0.6303 - accuracy: 0.7939\n",
            "Epoch 41/50\n",
            "5700/5700 [==============================] - 363s 64ms/step - loss: 0.6216 - accuracy: 0.7967\n",
            "Epoch 42/50\n",
            "5700/5700 [==============================] - 364s 64ms/step - loss: 0.6141 - accuracy: 0.7997\n",
            "Epoch 43/50\n",
            "5700/5700 [==============================] - 362s 64ms/step - loss: 0.6049 - accuracy: 0.8015\n",
            "Epoch 44/50\n",
            "5700/5700 [==============================] - 364s 64ms/step - loss: 0.5953 - accuracy: 0.8052\n",
            "Epoch 45/50\n",
            "5700/5700 [==============================] - 363s 64ms/step - loss: 0.5867 - accuracy: 0.8079\n",
            "Epoch 46/50\n",
            "5700/5700 [==============================] - 363s 64ms/step - loss: 0.5793 - accuracy: 0.8109\n",
            "Epoch 47/50\n",
            "5700/5700 [==============================] - 363s 64ms/step - loss: 0.5696 - accuracy: 0.8137\n",
            "Epoch 48/50\n",
            "5700/5700 [==============================] - 363s 64ms/step - loss: 0.5629 - accuracy: 0.8160\n",
            "Epoch 49/50\n",
            "5700/5700 [==============================] - 363s 64ms/step - loss: 0.5539 - accuracy: 0.8186\n",
            "Epoch 50/50\n",
            "5700/5700 [==============================] - 363s 64ms/step - loss: 0.5468 - accuracy: 0.8212\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hcofOhGT0ulK"
      },
      "source": [
        "pandas.DataFrame(history.history).to_csv(\"history.csv\")"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p3KOItizE7Vv"
      },
      "source": [
        "# Save and test using code from the Q4_Test\n",
        "model.save('LargeLSTM_model.h5')\n",
        "dump(mapping, open('LargeLSTM_mapping.pkl', 'wb'))\n"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "84heRAt7I9wQ"
      },
      "source": [
        "from pickle import load\n",
        "from keras.models import load_model\n",
        "from keras.utils import to_categorical\n",
        "from keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pI505c-PGW-r",
        "outputId": "3b3011e7-4e5b-4ad3-ac91-19197d297d92",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import string as str\n",
        "seed_text = 'It was the best of times, it was the worst of times, it was the age of wisdom, it was the age of foolishness, it was the epoch of belief, it was the epoch of incredulity, it was the season of Light, it was the season of Darkness, it was the spring of hope, it was the winter of despair,we had everything before us, we had nothing before us, we were all going direct to Heaven, we were all going direct the other way— '\n",
        "seed_text = seed_text.lower()\n",
        "seed_text = \"\".join(c for c in seed_text if c not in ('!','.',':',',',';','-','—'))\n",
        "n_chars_to_predict = 500\n",
        "seq_length = 20\n",
        "print(seed_text)\n"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "it was the best of times it was the worst of times it was the age of wisdom it was the age of foolishness it was the epoch of belief it was the epoch of incredulity it was the season of light it was the season of darkness it was the spring of hope it was the winter of despairwe had everything before us we had nothing before us we were all going direct to heaven we were all going direct the other way \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5U5iDHeLHXWG"
      },
      "source": [
        "# load the model and mapping\n",
        "model = load_model('LargeLSTM_model.h5')\n",
        "mapping = load(open('LargeLSTM_mapping.pkl', 'rb'))\n"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ks3TmiNImSO",
        "outputId": "7243c04e-a57e-44bd-b4d4-00d5664d85fc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Make predictions\n",
        "for k in range(n_chars_to_predict):\n",
        "    # encode the characters as integers\n",
        "    encoded = [mapping[char] for char in seed_text]\n",
        "    # truncate sequences to a fixed length\n",
        "    encoded = pad_sequences([encoded], maxlen=seq_length, truncating='pre')\n",
        "    # one hot encode\n",
        "    encoded = to_categorical(encoded, num_classes=len(mapping))\n",
        "    # predict character\n",
        "    yhat = model.predict_classes(encoded, verbose=0)\n",
        "    \n",
        "    # reverse map integer to character\n",
        "    for char, index in mapping.items():\n",
        "        if index == yhat:\n",
        "            break\n",
        "    seed_text += char\n",
        "\n",
        "print(seed_text)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 100, 28) for input Tensor(\"lstm_16_input_2:0\", shape=(None, 100, 28), dtype=float32), but it was called on an input with incompatible shape (None, 20, 28).\n",
            "it was the best of times it was the worst of times it was the age of wisdom it was the age of foolishness it was the epoch of belief it was the epoch of incredulity it was the season of light it was the season of darkness it was the spring of hope it was the winter of despairwe had everything before us we had nothing before us we were all going direct to heaven we were all going direct the other way in his answer was to deliver it to be the only one things to be a little angry and seeming to be sure that he was the family s confidence into the courtyard here and from the great gentleman who was not a sigh nor confiscation and settled more and more disturbed. with the bastille citizen defarge stood striking his wife and child he said with a cries from the prisoner s hand and his face which had been taken in a corner where he laid her hand upon his head against the wall on the table between t\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OBFQ4wjWiR6Q"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}